{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f280c44-f5ea-4c44-9a95-bb4711cbd5a6",
   "metadata": {},
   "source": [
    "# Example download script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8746e-c7e8-44d8-b66d-f365a69a8f6e",
   "metadata": {},
   "source": [
    "How about https://pydataverse.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b1a89-85d0-4e79-b540-5c845101e74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07068c6-6f22-43ba-93fd-2b8e6a6ebdd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:30:32.873078Z",
     "iopub.status.busy": "2025-03-31T12:30:32.872821Z",
     "iopub.status.idle": "2025-03-31T12:30:32.939643Z",
     "shell.execute_reply": "2025-03-31T12:30:32.939265Z",
     "shell.execute_reply.started": "2025-03-31T12:30:32.873056Z"
    }
   },
   "outputs": [],
   "source": [
    "# This script contains functions to inspect and download files from a dataset in the Archaeology Data Station repository.\n",
    "# Author: Alessandra Polimeno (DANS-KNAW)\n",
    "\n",
    "\n",
    "# The format of the DOIs should have the following structure: \"10.17026/dans-xxx-xx0x\"\n",
    "# They can be found under the column \"dsPersistentID\"\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b804baa-5c9c-4b35-9d81-22e130314218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:22:54.984377Z",
     "iopub.status.busy": "2025-03-31T15:22:54.984110Z",
     "iopub.status.idle": "2025-03-31T15:22:55.071654Z",
     "shell.execute_reply": "2025-03-31T15:22:55.071022Z",
     "shell.execute_reply.started": "2025-03-31T15:22:54.984357Z"
    }
   },
   "outputs": [],
   "source": [
    "persistent_id = '10.34894/MSBW8A' \n",
    "\n",
    "#url = f\"http://archaeology.datastations.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}\"\n",
    "\n",
    "# also not correct: \n",
    "#url = f'https://dataverse.nl/dataset.xhtml?persistentId=doi:{persistent_id}' \n",
    "\n",
    "# third trial\n",
    "url = f'https://dataverse.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}' \n",
    "params = {\"persistent_id\": persistent_id}\n",
    "\n",
    "response = requests.get(url, params=params, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14d50857-896e-4ba5-999a-270d96d292ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T14:37:28.174016Z",
     "iopub.status.busy": "2025-03-31T14:37:28.173774Z",
     "iopub.status.idle": "2025-03-31T14:37:28.176583Z",
     "shell.execute_reply": "2025-03-31T14:37:28.176136Z",
     "shell.execute_reply.started": "2025-03-31T14:37:28.173996Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b00cc150-fa96-468b-a705-a5940984917b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:24:05.354351Z",
     "iopub.status.busy": "2025-03-31T15:24:05.354070Z",
     "iopub.status.idle": "2025-03-31T15:24:05.780819Z",
     "shell.execute_reply": "2025-03-31T15:24:05.780194Z",
     "shell.execute_reply.started": "2025-03-31T15:24:05.354330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016003 Dorestad D16 Logboek.pdf', '2016003 Dorestad meetreeksen 1 tot en met 10.fh', 'MANIFEST.TXT']\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print_all_files('10.34894/MSBW8A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05e4f221-a298-4749-85dd-9b2ceca116da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:26:05.790512Z",
     "iopub.status.busy": "2025-03-31T15:26:05.790265Z",
     "iopub.status.idle": "2025-03-31T15:26:06.156702Z",
     "shell.execute_reply": "2025-03-31T15:26:06.156015Z",
     "shell.execute_reply.started": "2025-03-31T15:26:05.790489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: 2016003 Dorestad D16 Logboek.pdf\n",
      "Extracted: 2016003 Dorestad meetreeksen 1 tot en met 10.fh\n",
      "Extracted: MANIFEST.TXT\n",
      "All files saved to 'downloads/10.34894%MSBW8A'\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "download_all_files('10.34894/MSBW8A', 'downloads')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc9767-3d1e-4896-bfba-82366628fdd9",
   "metadata": {},
   "source": [
    "Dendro data is deposited at: https://dataverse.nl/dataverse/dccd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc3584-482d-41c1-8953-76a5a91fe098",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c63cdea-aea6-4c1c-9a5d-e3e821ac0876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:25:30.158584Z",
     "iopub.status.busy": "2025-03-31T15:25:30.158253Z",
     "iopub.status.idle": "2025-03-31T15:25:30.220493Z",
     "shell.execute_reply": "2025-03-31T15:25:30.219998Z",
     "shell.execute_reply.started": "2025-03-31T15:25:30.158554Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_all_files(persistent_id):\n",
    "    \"\"\"\n",
    "    Print all files in a dataset with the given persistent ID.\n",
    "\n",
    "    :param persistent_id: The persistent ID of the dataset.\n",
    "\n",
    "    \"\"\"\n",
    "    # this is the original url: \n",
    "    #url = f\"http://archaeology.datastations.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}\"\n",
    "    \n",
    "    # this is my first trial (not working) \n",
    "    #url = f'https://dataverse.nl/dataset.xhtml?persistentId=doi:{persistent_id}' \n",
    "\n",
    "    # second trial (also not working)\n",
    "    #url = f'https://dataverse.nl/api/access/dataset/:persistentId=doi:{persistent_id}' \n",
    "\n",
    "    #third trial(works!)\n",
    "    url = f'https://dataverse.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}' \n",
    "\n",
    "    params = {\"persistent_id\": persistent_id}\n",
    "\n",
    "    response = requests.get(url, params=params, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "            print(zip_file.namelist())\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "    print(\"=================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_all_files(persistent_id, output_path):\n",
    "    \"\"\"\n",
    "    Download all files from a dataset with the given persistent ID.\n",
    "\n",
    "    :param persistent_id: The persistent ID of the dataset.\n",
    "    :param output_path: The path to the directory where the files will be saved. If the directory does not exist, it will be created.\n",
    "\n",
    "    \"\"\"\n",
    "    #url = f\"http://archaeology.datastations.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}\"\n",
    "\n",
    "    url = f'https://dataverse.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}' \n",
    "    params = {\"persistent_id\": persistent_id}\n",
    "\n",
    "    output_doi = persistent_id.replace(\"/\", \"%\")\n",
    "    output_dir = f\"{output_path}/{output_doi}\"\n",
    "\n",
    "    response = requests.get(url, params=params, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            for file_name in zip_file.namelist():\n",
    "                zip_file.extract(file_name, output_dir)\n",
    "                print(f\"Extracted: {file_name}\")\n",
    "\n",
    "        print(f\"All files saved to '{output_dir}'\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")   \n",
    "    \n",
    "    print(\"=================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_selected_files(persistent_id, selected_files, output_path):\n",
    "    \"\"\"\n",
    "    Download selected files from a dataset with the given persistent ID. You select the files by providing a list of filenames.\n",
    "    Even if you want to download only one file, you need to provide the filename as a list.\n",
    "\n",
    "    :param persistent_id: The persistent ID of the dataset.\n",
    "    :param selected_files: A list containing the filenames to be downloaded.\n",
    "    :param output_path: The path to the directory where the files will be saved. If the directory does not exist, it will be created.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"http://archaeology.datastations.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}\"\n",
    "    params = {\"persistent_id\": persistent_id}\n",
    "\n",
    "    output_doi = persistent_id.replace(\"/\", \"%\")\n",
    "    output_dir = f\"{output_path}/{output_doi}\"\n",
    "\n",
    "    response = requests.get(url, params=params, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            zip_filenames = set(zip_file.namelist())  # Get all files in the ZIP\n",
    "            print(zip_filenames)\n",
    "            found_files = selected_files.intersection(zip_filenames)\n",
    "            # missing_files = selected_files - zip_filenames  # Files that are missing\n",
    "\n",
    "            for file_name in found_files:\n",
    "                zip_file.extract(file_name, output_dir)\n",
    "                print(f\"Extracted: {file_name}\")\n",
    "\n",
    "            #if missing_files:\n",
    "            #    print(f\"Warning: The following files were not found in the ZIP: {missing_files}\")\n",
    "\n",
    "        print(f\"Selected files saved to '{output_dir}'\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "    print(\"=================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_specific_filetype(persistent_id, output_path, filetype): \n",
    "    \"\"\"\n",
    "    Download all files of a given filetype from the dataset with the specified persistent ID.\n",
    "\n",
    "    :param persistent_id: The persistent ID of the dataset.\n",
    "    :param output_path: The path to the directory where the PDF files will be saved. If the directory does not exist, it will be created.\n",
    "    :param filetype: The file type to be downloaded as a string, e.g. 'xml'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"http://archaeology.datastations.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}\"\n",
    "    params = {\"persistent_id\": persistent_id}\n",
    "\n",
    "    output_doi = persistent_id.replace(\"/\", \"%\")\n",
    "    output_dir = f\"{output_path}/{output_doi}\"\n",
    "\n",
    "    response = requests.get(url, params=params, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            zip_filenames = set(zip_file.namelist())  # Get all files in the ZIP\n",
    "            print(zip_filenames)\n",
    "            selected_files = {file_name for file_name in zip_filenames if file_name.endswith(f'{filetype}')}\n",
    "\n",
    "            for file_name in selected_files:\n",
    "                zip_file.extract(file_name, output_dir)\n",
    "                print(f\"Extracted: {file_name}\")\n",
    "\n",
    "        print(f\"{filetype} files saved to '{output_dir}'\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "    print(\"=================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe93770-4563-4259-845f-6424f178ec71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
