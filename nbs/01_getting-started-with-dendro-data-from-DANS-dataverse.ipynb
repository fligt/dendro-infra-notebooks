{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f280c44-f5ea-4c44-9a95-bb4711cbd5a6",
   "metadata": {},
   "source": [
    "# Getting started with dendro data from DANS dataverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6919f0-0abb-4799-b6aa-8eba43ae878c",
   "metadata": {},
   "source": [
    "*In this Jupyter notebook I try to download and query dendrochronology data from the DANS dataverse repository. To do this I adapted the [python script](https://github.com/Dans-labs/rce-spatial-coverage/blob/master/scripts/download_ds_files.py) by Alessandra Polimeno (DANS-KNAW).* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a7609-a6c3-4e8c-b8bc-b4dd05de29a3",
   "metadata": {},
   "source": [
    "## A first example of downloading all files in a specific record "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad192d-3726-46cb-8a17-033a19a67854",
   "metadata": {},
   "source": [
    "In order to locate a dendrochronology record persistent identifier I opened https://dataverse.nl/ in my web browser, entered `dccd` in the search box. We arrive at a collection of datasets by a large amount of organizations: https://dataverse.nl/dataverse/dccd. Some datasets seem to be restricted. Next, I selected `Stichting Ring` with fully open data. This then opens a page with 2459 open records: https://dataverse.nl/dataverse/stichtingring. \n",
    "\n",
    "The very first record is this Dorestad series: https://dataverse.nl/dataset.xhtml?persistentId=doi:10.34894/MSBW8A. The last part of the url contains the persistent identifier: `'10.34894/MSBW8A'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe204b4-2bc3-465d-85d9-9a26affafe3e",
   "metadata": {},
   "source": [
    "The filenames in this record can be printed with the `print_all_files()` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e12f21-adbf-4d6e-a057-4c80e1d0e59d",
   "metadata": {},
   "source": [
    "> IMPORTANT NOTE: RUN THE 'FUNCTIONS' CODE CELL AT THE END OF THIS NOTEBOOK FIRST BEFORE EXECUTING THESE EXAMPLES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b00cc150-fa96-468b-a705-a5940984917b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T14:57:08.906961Z",
     "iopub.status.busy": "2025-04-01T14:57:08.906723Z",
     "iopub.status.idle": "2025-04-01T14:57:09.435648Z",
     "shell.execute_reply": "2025-04-01T14:57:09.435003Z",
     "shell.execute_reply.started": "2025-04-01T14:57:08.906941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016003 Dorestad D16 Logboek.pdf', '2016003 Dorestad meetreeksen 1 tot en met 10.fh', 'MANIFEST.TXT']\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print_all_files('10.34894/MSBW8A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fed5c1-fbc6-4d2d-bfc0-0cbbcc412371",
   "metadata": {},
   "source": [
    "And can be downloaded to a folder in your file system with the function `download_all_files()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e4f221-a298-4749-85dd-9b2ceca116da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T10:07:54.450500Z",
     "iopub.status.busy": "2025-04-01T10:07:54.450331Z",
     "iopub.status.idle": "2025-04-01T10:07:54.802214Z",
     "shell.execute_reply": "2025-04-01T10:07:54.801695Z",
     "shell.execute_reply.started": "2025-04-01T10:07:54.450486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: 2016003 Dorestad D16 Logboek.pdf\n",
      "Extracted: 2016003 Dorestad meetreeksen 1 tot en met 10.fh\n",
      "Extracted: MANIFEST.TXT\n",
      "All files saved to '../../data/downloads/10.34894%MSBW8A'\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "download_all_files('10.34894/MSBW8A', '../../data/downloads')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ab6a2-a777-4f61-8ebc-e11aa866f020",
   "metadata": {},
   "source": [
    "However, if I look at the first record DOI of the complete DCCD, I get this error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97e6d1a0-73b3-4fc9-8d7b-a884d93c5a25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T14:54:37.752557Z",
     "iopub.status.busy": "2025-04-01T14:54:37.752319Z",
     "iopub.status.idle": "2025-04-01T14:54:37.834357Z",
     "shell.execute_reply": "2025-04-01T14:54:37.833888Z",
     "shell.execute_reply.started": "2025-04-01T14:54:37.752537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 403, {\"status\":\"ERROR\",\"code\":403,\"message\":\"Not authorized to access this object via this API endpoint. Please check your code for typos, or consult our API guide at http://guides.dataverse.org.\",\"requestUrl\":\"https://dataverse.nl/api/v1/access/dataset/:persistentId?persistentId=doi:10.34894/CKVQTX&persistent_id=10.34894%2FCKVQTX\",\"requestMethod\":\"GET\"}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print_all_files('10.34894/CKVQTX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d160a-8602-471c-bc8a-04cf6b4d174d",
   "metadata": {},
   "source": [
    "Let's explore this further in the next notebook `02_Dataverse-search-API.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc3584-482d-41c1-8953-76a5a91fe098",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c58f23-2670-49d2-a45b-c987992eaf20",
   "metadata": {},
   "source": [
    "You need to run this code cell first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40b2d1-3b88-406b-b716-0749b3c05d77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T10:06:59.184824Z",
     "iopub.status.busy": "2025-04-01T10:06:59.184573Z",
     "iopub.status.idle": "2025-04-01T10:06:59.197474Z",
     "shell.execute_reply": "2025-04-01T10:06:59.197004Z",
     "shell.execute_reply.started": "2025-04-01T10:06:59.184803Z"
    }
   },
   "outputs": [],
   "source": [
    "# This python script was adapted by Frank Ligterink from:  \n",
    "# https://github.com/Dans-labs/rce-spatial-coverage/blob/master/scripts/download_ds_files.py\n",
    "# This script contains functions to inspect and download files from a dataset in the Archaeology Data Station repository.\n",
    "# Author: Alessandra Polimeno (DANS-KNAW)\n",
    "\n",
    "# The format of the DOIs should have the following structure: \"10.17026/dans-xxx-xx0x\"\n",
    "# They can be found under the column \"dsPersistentID\"\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "\n",
    "def print_all_files(persistent_id):\n",
    "    \"\"\"\n",
    "    Print all files in a dataset with the given persistent ID.\n",
    "\n",
    "    :param persistent_id: The persistent ID of the dataset. \n",
    "    \"\"\" \n",
    "    \n",
    "    # this is the original url by Alessandra: \n",
    "    #url = f\"http://archaeology.datastations.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}\"\n",
    "\n",
    "    # this new url works for our dendro data \n",
    "    url = f'https://dataverse.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}' \n",
    "    params = {\"persistent_id\": persistent_id}\n",
    "    response = requests.get(url, params=params, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "            print(zip_file.namelist())\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "    print(\"=================================================================\")\n",
    "\n",
    "\n",
    "def download_all_files(persistent_id, output_path):\n",
    "    \"\"\"\n",
    "    Download all files from a dataset with the given persistent ID.\n",
    "\n",
    "    :param persistent_id: The persistent ID of the dataset.\n",
    "    :param output_path: The path to the directory where the files will be saved. If the directory does not exist, it will be created.\n",
    "\n",
    "    \"\"\"\n",
    "    #url = f\"http://archaeology.datastations.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}\"\n",
    "\n",
    "    url = f'https://dataverse.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}' \n",
    "    params = {\"persistent_id\": persistent_id}\n",
    "\n",
    "    output_doi = persistent_id.replace(\"/\", \"%\")\n",
    "    output_dir = f\"{output_path}/{output_doi}\"\n",
    "\n",
    "    response = requests.get(url, params=params, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            for file_name in zip_file.namelist():\n",
    "                zip_file.extract(file_name, output_dir)\n",
    "                print(f\"Extracted: {file_name}\")\n",
    "\n",
    "        print(f\"All files saved to '{output_dir}'\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")   \n",
    "    \n",
    "    print(\"=================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_selected_files(persistent_id, selected_files, output_path):\n",
    "    \"\"\"\n",
    "    Download selected files from a dataset with the given persistent ID. You select the files by providing a list of filenames.\n",
    "    Even if you want to download only one file, you need to provide the filename as a list.\n",
    "\n",
    "    :param persistent_id: The persistent ID of the dataset.\n",
    "    :param selected_files: A list containing the filenames to be downloaded.\n",
    "    :param output_path: The path to the directory where the files will be saved. If the directory does not exist, it will be created.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"http://archaeology.datastations.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}\"\n",
    "    params = {\"persistent_id\": persistent_id}\n",
    "\n",
    "    output_doi = persistent_id.replace(\"/\", \"%\")\n",
    "    output_dir = f\"{output_path}/{output_doi}\"\n",
    "\n",
    "    response = requests.get(url, params=params, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            zip_filenames = set(zip_file.namelist())  # Get all files in the ZIP\n",
    "            print(zip_filenames)\n",
    "            found_files = selected_files.intersection(zip_filenames)\n",
    "            # missing_files = selected_files - zip_filenames  # Files that are missing\n",
    "\n",
    "            for file_name in found_files:\n",
    "                zip_file.extract(file_name, output_dir)\n",
    "                print(f\"Extracted: {file_name}\")\n",
    "\n",
    "            #if missing_files:\n",
    "            #    print(f\"Warning: The following files were not found in the ZIP: {missing_files}\")\n",
    "\n",
    "        print(f\"Selected files saved to '{output_dir}'\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "    print(\"=================================================================\")\n",
    "\n",
    "\n",
    "def download_specific_filetype(persistent_id, output_path, filetype): \n",
    "    \"\"\"\n",
    "    Download all files of a given filetype from the dataset with the specified persistent ID.\n",
    "\n",
    "    :param persistent_id: The persistent ID of the dataset.\n",
    "    :param output_path: The path to the directory where the PDF files will be saved. If the directory does not exist, it will be created.\n",
    "    :param filetype: The file type to be downloaded as a string, e.g. 'xml'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"http://archaeology.datastations.nl/api/access/dataset/:persistentId?persistentId=doi:{persistent_id}\"\n",
    "    params = {\"persistent_id\": persistent_id}\n",
    "\n",
    "    output_doi = persistent_id.replace(\"/\", \"%\")\n",
    "    output_dir = f\"{output_path}/{output_doi}\"\n",
    "\n",
    "    response = requests.get(url, params=params, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            zip_filenames = set(zip_file.namelist())  # Get all files in the ZIP\n",
    "            print(zip_filenames)\n",
    "            selected_files = {file_name for file_name in zip_filenames if file_name.endswith(f'{filetype}')}\n",
    "\n",
    "            for file_name in selected_files:\n",
    "                zip_file.extract(file_name, output_dir)\n",
    "                print(f\"Extracted: {file_name}\")\n",
    "\n",
    "        print(f\"{filetype} files saved to '{output_dir}'\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "    print(\"=================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe93770-4563-4259-845f-6424f178ec71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
